: 75
all: 1
help: 1
when: 1
automated: 1
Hadoop: 4
"local": 1
including: 3
computation: 1
["Third: 1
file: 1
high-level: 1
find: 1
web: 1
Shell: 2
cluster: 2
how: 2
using:: 1
Big: 1
guidance: 3
run:: 1
Scala,: 1
Running: 1
should: 2
environment: 1
to: 14
only: 1
given.: 1
rich: 1
directory.: 1
Apache: 1
Interactive: 2
sc.parallelize(range(1000)).count(): 1
Building: 1
do: 2
guide,: 1
return: 2
which: 2
Programs: 1
Many: 1
Try: 1
built,: 1
"yarn-client": 1
YARN,: 1
not: 1
using: 2
Example: 1
scala>: 1
Once: 1
documentation,: 1
Because: 1
cluster.: 1
name: 1
Maven"](http://spark.apache.org/docs/latest/building-with-maven.html).: 1
Testing: 1
Streaming: 1
./bin/pyspark: 1
SQL: 2
through: 1
GraphX: 1
them,: 1
[run: 1
"yarn-cluster": 1
the: 21
abbreviated: 1
set: 2
[project: 2
Scala: 2
##: 8
thread,: 1
library: 1
see: 1
examples: 2
MASTER: 1
runs.: 1
[Apache: 1
Pi: 1
instructions.: 1
More: 1
Python,: 2
#: 1
processing,: 2
for: 11
optimized: 1
its: 1
version: 1
wiki](https://cwiki.apache.org/confluence/display/SPARK).: 1
provides: 1
print: 1
Configuration: 1
supports: 2
command,: 2
[params]`.: 1
refer: 2
available: 1
be: 2
run: 7
./bin/run-example: 2
Versions: 1
This: 2
Hadoop,: 2
Documentation: 1
use: 3
downloaded: 1
distributions.: 1
Spark.: 1
example:: 1
`examples`: 2
-DskipTests: 1
Maven](http://maven.apache.org/).: 1
["Building: 1
works: 1
package: 1
of: 5
changed: 1
programming: 1
Spark: 15
against: 1
site,: 1
graph: 1
For: 2
or: 3
mvn: 1
learning,: 1
and: 10
contains: 1
stream: 1
can: 6
overview: 1
package.): 1
Please: 3
one: 2
Note: 1
Data.: 1
(You: 1
Online: 1
tools: 1
your: 1
threads.: 1
Tests: 1
fast: 1
from: 1
package.: 1
APIs: 1
SparkPi: 2
structured: 1
system: 1
submit: 1
systems.: 1
start: 1
Version"](http://spark.apache.org/docs/latest/building-with-maven.html#specifying-the-hadoop-version): 1
params: 1
Hadoop-supported: 1
way: 1
basic: 1
README: 1
<http://spark.apache.org/>: 1
It: 2
graphs: 1
Spark](#building-spark).: 1
engine: 1
building: 3
configure: 1
on: 6
N: 1
usage: 1
"local[N]": 1
>>>: 1
particular: 3
instance:: 1
./bin/spark-shell: 1
general: 2
with: 5
easiest: 1
protocols: 1
must: 1
And: 1
also: 5
versions: 1
this: 1
setup: 1
page](http://spark.apache.org/documentation.html): 1
shell:: 2
will: 1
See: 1
`./bin/run-example: 1
guide](http://spark.apache.org/docs/latest/configuration.html): 1
following: 2
locally: 2
distribution: 1
example: 3
are: 1
detailed: 2
tests](https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark#ContributingtoSpark-AutomatedTesting).: 1
mesos://: 1
project: 1
computing: 1
URL,: 1
is: 6
in: 5
higher-level: 1
tests: 1
1000:: 2
an: 3
sample: 1
To: 2
at: 2
have: 1
1000).count(): 1
["Specifying: 1
Party: 1
[building: 1
You: 3
if: 4
different: 1
MASTER=spark://host:7077: 1
no: 1
programs,: 1
Java,: 1
that: 3
storage: 1
MLlib: 1
same: 1
machine: 1
application: 1
need: 1
other: 1
analysis.: 1
build: 3
prefer: 1
online: 1
you: 4
several: 1
A: 1
distribution.: 1
About: 1
HDFS: 1
[Configuration: 1
sc.parallelize(1: 1
locally.: 1
Hive: 2
running: 1
uses: 1
a: 9
variable: 1
The: 1
data: 2
class: 2
built: 1
Distributions"](http://spark.apache.org/docs/latest/hadoop-third-party-distributions.html): 1
Thriftserver: 1
processing.: 1
programs: 2
requires: 1
documentation: 3
pre-built: 1
Alternatively,: 1
Python: 2
./dev/run-tests: 1
comes: 1
clean: 1
<class>: 1
spark://: 1
first: 1
core: 1
talk: 1
latest: 1
